{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "my_var = tf.Variable(tf.zeros([2,3]))\n",
    "sess = tf.Session()\n",
    "initialize_op = tf.global_variables_initializer()\n",
    "print sess.run(initialize_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.global_variables_initializer() used to initilize every variables\n",
    "#### We can also use variable.initialize to initialize everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7410866 ,  0.84648043],\n",
       "       [ 0.37969205,  0.10851682]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "x = tf.placeholder(tf.float32,shape=[2,2])\n",
    "y = tf.identity(x)\n",
    "x_vals = np.random.rand(2,2)\n",
    "sess.run(y,feed_dict={x:x_vals})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize variables multiple times will generate different result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.03809404  0.96586078  0.77716315]\n",
      " [ 0.98145044  0.96891814  0.77859271]]\n",
      "[[ 1.10784531  0.95900738  1.18663287]\n",
      " [ 1.33419776  1.08003914  1.29110038]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "A = tf.truncated_normal([2,3],mean=1,stddev=0.25)\n",
    "print(sess.run(A))\n",
    "print(sess.run(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert_to_tensor will transform data in other format to tensor, while it's highly recommended to add a parameter to decide its type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.31757343  1.08780634]\n",
      " [ 1.19445705  1.2622205 ]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.convert_to_tensor(np.array([[1,0],[0,1]]),dtype=tf.float32)\n",
    "b = tf.truncated_normal([2,2],mean=1,stddev=0.25)\n",
    "print(sess.run(tf.matmul(a,b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix_determinant can be used to calculate the determinant of a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.54262\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.matrix_determinant(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix_inverse\n",
    "- Based on cholesky decomposition if symmetrix positive definite\n",
    "- Or LU decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.73915255  1.33987892]\n",
      " [ 1.35822368 -0.93837321]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.matrix_inverse(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.99999046e-01   0.00000000e+00]\n",
      " [  1.90734863e-06   1.00000095e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.matmul(tf.matrix_inverse(b),b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigen decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.27819246,  2.65784049], dtype=float32), array([[-0.70613968,  0.70807266],\n",
      "       [ 0.70807266,  0.70613968]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.self_adjoint_eig(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first row it eigen values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic operations on tensors\n",
    "- add()\n",
    "- sub()\n",
    "- mul()\n",
    "- div()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while sub() is like // if inputs are integers, to maintain to be / we need to use truediv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.div(3,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.truediv(3,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "floordiv() will return a float rounding down to the nearest integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.floordiv(33.5,7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also sin functions and cos functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.div(tf.sin(3.1416/4),tf.cos(3.1416/4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our own function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12.  54.  14.]\n"
     ]
    }
   ],
   "source": [
    "def polynomial(value):\n",
    "    return (tf.subtract(3 * tf.square(value),value)+10)\n",
    "print(sess.run(polynomial(tf.convert_to_tensor([1,4,-1],dtype=tf.float32))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.subtract(3,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   3.  10.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.nn.relu([-3.,3.,10.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Better version of ReLU, ReLU6\n",
    "- min(max(0,x),6)\n",
    "- hard-sigmoid function\n",
    "- computationally faster\n",
    "- does not suffer from vanishing or exploding values\n",
    "- good in DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  3.  6.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.nn.relu6([-3,3,10.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The legend, sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- smooth, continuous\n",
    "- tendency to zero-out the back propagation terms\n",
    "- [0,1]\n",
    "- Not zero-centered, which require us to zero-mean the data in the first place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04742587  0.5         0.95257413]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.nn.sigmoid([-3,0,3.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiper tangent\n",
    "- [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.76159418  0.          0.76159418]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.nn.tanh([-1.,0.,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softsign\n",
    "x/abs(x)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5  0.   0.5]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.nn.softsign([-1,0.,1.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softplus\n",
    "log(exp(x)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.31326166  0.69314718  1.31326163]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.nn.softplus([-1.,0.,1.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Linear Unit(ELU)\n",
    "better version of softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.63212055  0.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.nn.elu([-1.,0.,1.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAW THE STUPID GRAPH FROM THESE ACTIVATION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
